{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from utils import select_available, plot_figure, save_gif\n",
    "\n",
    "device = select_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(channels_in, channels_out, bias=True),\n",
    "            nn.GELU()\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "    \n",
    "class CosActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cos(x)\n",
    "\n",
    "class FourierBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        layers_sin = [\n",
    "            nn.Linear(channels_in, channels_out, bias=False),\n",
    "            SinActivation(),\n",
    "        ]\n",
    "        layers_cos = [\n",
    "            nn.Linear(channels_in, channels_out, bias=False),\n",
    "            CosActivation(),\n",
    "        ]\n",
    "        \n",
    "        self.layers_sin = nn.Sequential(*layers_sin)\n",
    "        self.layers_cos = nn.Sequential(*layers_cos)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sin_part = self.layers_sin(x)\n",
    "        cos_part = self.layers_cos(x)\n",
    "        return sin_part + cos_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_layers, output_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.fc_in = LinearBlock(input_features, hidden_layers[0])\n",
    "        self.fc_in = FourierBlock(input_features, hidden_layers[0])\n",
    "\n",
    "        layers = []\n",
    "        if len(hidden_layers) > 1:\n",
    "            for i in range(len(hidden_layers) - 1):\n",
    "                # layers.append(LinearBlock(hidden_layers[i], hidden_layers[i+1]))\n",
    "                layers.append(FourierBlock(hidden_layers[i], hidden_layers[i+1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_layers[-1], output_features, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y'(x) = x + y \\text{;  } y(0) = 0$\n",
    "\n",
    "$y(x) = e^x - x - 1 $\n",
    "\n",
    "$y(x) \\approx x N(x)$\n",
    "\n",
    "$x N'(x) + N(x) = x + x N(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# def sol(x):\n",
    "#     return torch.exp(x) - x - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ y'(x) = 3y + 4; y(0) = 0$\n",
    "\n",
    "$ y(x) = \\frac{4}{3}(e^{3x} - 1)$\n",
    "\n",
    "$ y(x) \\approx x N(x) $\n",
    "\n",
    "$ x N'(x) + N(x) = 3 x N(x) + 4 $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x, y):\n",
    "#     return 3 * y + 4\n",
    "\n",
    "# def sol(x):\n",
    "#     return 4 / 3 * (torch.exp(3 * x) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y'(x) = \\frac{1}{x}; y(1) = 0 $\n",
    "\n",
    "$ y(x) = ln|x| $\n",
    "\n",
    "$ y(x) \\approx (1 - x) N(x) $\n",
    "\n",
    "$ (1 - x) N'(x) - N(x) = \\frac{1}{x} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "    return 1 / x\n",
    "\n",
    "def sol(x):\n",
    "    return torch.log(torch.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y'(x) = - y\\text{ tan}(x) + \\text{sin}(x) $\n",
    "\n",
    "$y(0) = 0 $\n",
    "\n",
    "$y(x) = \\frac{1}{ \\text{cos}(x)} -  \\text{cos}(x) $\n",
    "\n",
    "$y(x) \\approx x N(x) $\n",
    "\n",
    "$ x N'(x) + N(x) = - x N(x) \\text{ tan}(x) + \\text{sin}(x) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "    return - y * torch.tan(x) + torch.sin(x)\n",
    "\n",
    "def sol(x):\n",
    "    return 1 / torch.cos(x) - torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import shutil\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def train(model, domain, num_epochs, optimizer, loss_fn, plot_interval, model_name, atol=1e-5):\n",
    "\n",
    "    images = []\n",
    "    last_save_path = False\n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training Progress\", ncols=100)\n",
    "\n",
    "    solution = sol(domain)\n",
    "    for epoch in epoch_pbar:\n",
    "        optimizer.zero_grad()\n",
    "        domain.requires_grad_(True)\n",
    "\n",
    "        outputs = model(domain)\n",
    "        \n",
    "        gradients = torch.autograd.grad(outputs, domain, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "        \n",
    "        # loss_domain = loss_fn(gradients, func(domain, outputs))\n",
    "        # loss_boundary = loss_fn(model(torch.tensor([0.0])), torch.tensor([0.0]))\n",
    "        # loss = loss_domain + loss_boundary \n",
    "        loss = loss_fn(domain * gradients + outputs, func(domain, domain * outputs))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        epoch_pbar.set_postfix_str(f\"Train Loss: {loss.item():.8f}\", refresh=True)\n",
    "\n",
    "        if 0 < loss.item() < atol:\n",
    "            print(f'Stopping criterion met at epoch {epoch}: Loss is less than {atol}.')\n",
    "            last_save_path = plot_figure(domain.detach(), solution, domain.detach() * outputs.detach(), model, epoch, loss, figure_name=model_name)\n",
    "            \n",
    "            break\n",
    "        \n",
    "    # - - GIF SAVING - - \n",
    "    \n",
    "        if epoch % plot_interval == 0 or epoch == num_epochs - 1:            \n",
    "            save_path = plot_figure(domain.detach(), solution, domain.detach() * outputs.detach(), model, epoch, loss, figure_name=model_name)\n",
    "            images.append(save_path)\n",
    "    \n",
    "    if last_save_path:\n",
    "        images.append(last_save_path)\n",
    "    save_gif(model_name, images)\n",
    "    \n",
    "    if os.path.exists(model_name):\n",
    "        shutil.rmtree(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|█████████████| 10000/10000 [01:14<00:00, 135.03it/s, Train Loss: 0.00056961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved at gif/MLP_100_100_cas.gif\n"
     ]
    }
   ],
   "source": [
    "domain = torch.linspace(0.0, 1.5, steps=100).unsqueeze(1)\n",
    "solution = sol(domain.detach())\n",
    "\n",
    "features_in = 1\n",
    "features_out = 1\n",
    "hidden = [100, 100]\n",
    "\n",
    "model = MLP(features_in, hidden, features_out)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10000\n",
    "images = train(model, domain, epochs, optimizer, loss_fn, plot_interval=10, model_name=f\"MLP_{'_'.join(map(str, hidden))}_cas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 20301\n",
      "Prediction at x=0.4000: -1.2395\n",
      "Derivative at x=0.4000: 0.3969\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "func() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction at x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_point\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDerivative at x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_point\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_point\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact value at x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_point\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_point\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDerivative at x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_point\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_func_dx(x_point)\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: func() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f'Model parameter count: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "x_point = torch.tensor([0.4], requires_grad=True)\n",
    "output = model(x_point)\n",
    "output.backward()\n",
    "\n",
    "print(f\"Prediction at x={x_point.item():.4f}: {output.item():.4f}\")\n",
    "print(f\"Derivative at x={x_point.item():.4f}: {x_point.grad.item():.4f}\")\n",
    "\n",
    "print(f\"Exact value at x={x_point.item():.4f}: {func(x_point).item():.4f}\")\n",
    "print(f\"Derivative at x={x_point.item():.4f}: {d_func_dx(x_point).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
