{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from utils import select_available, train\n",
    "\n",
    "device = select_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(channels_in, channels_out, bias=True),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "    \n",
    "class CosActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cos(x)\n",
    "\n",
    "class FourierBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        layers_sin = [\n",
    "            nn.Linear(channels_in, channels_out, bias=False),\n",
    "            SinActivation(),\n",
    "        ]\n",
    "        layers_cos = [\n",
    "            nn.Linear(channels_in, channels_out, bias=False),\n",
    "            CosActivation(),\n",
    "        ]\n",
    "        \n",
    "        self.layers_sin = nn.Sequential(*layers_sin)\n",
    "        self.layers_cos = nn.Sequential(*layers_cos)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sin_part = self.layers_sin(x)\n",
    "        cos_part = self.layers_cos(x)\n",
    "        return sin_part + cos_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_layers, output_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_in = LinearBlock(input_features, hidden_layers[0])\n",
    "        # self.fc_in = FourierBlock(input_features, hidden_layers[0])\n",
    "\n",
    "        layers = []\n",
    "        if len(hidden_layers) > 1:\n",
    "            for i in range(len(hidden_layers) - 1):\n",
    "                layers.append(LinearBlock(hidden_layers[i], hidden_layers[i+1]))\n",
    "                # layers.append(FourierBlock(hidden_layers[i], hidden_layers[i+1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_layers[-1], output_features, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x**2\n",
    "    # return x**2 - torch.exp(-2*x**2)\n",
    "    # return torch.sin(x) + torch.cos(3*x) + torch.sin(5*x)\n",
    "\n",
    "def d_func_dx(x):\n",
    "    return 2*x\n",
    "    # return 2*x + 4*x*torch.exp(-2*x**2)\n",
    "    # return torch.cos(x) - 3*torch.sin(3*x) + 5*torch.cos(5*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████| 1000/1000 [00:06<00:00, 162.88it/s, Train Loss: 0.00003181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved at gif/MLP_100_100_relu.gif\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.linspace(-np.pi, np.pi, 200).unsqueeze(1)\n",
    "y_train = func(x_train)\n",
    "\n",
    "features_in = 1\n",
    "features_out = 1\n",
    "hidden = [100, 100]\n",
    "\n",
    "model = MLP(features_in, hidden, features_out)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "images = train(model, x_train, y_train, epochs, optimizer, loss_fn, plot_interval=10, model_name=f\"MLP_{'_'.join(map(str, hidden))}_relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 10401\n",
      "Prediction at x=0.4000: 0.1479\n",
      "Derivative at x=0.4000: 0.6327\n",
      "Exact value at x=0.4000: 0.1600\n",
      "Derivative at x=0.4000: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f'Model parameter count: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "x_point = torch.tensor([0.4], requires_grad=True)\n",
    "output = model(x_point)\n",
    "output.backward()\n",
    "\n",
    "print(f\"Prediction at x={x_point.item():.4f}: {output.item():.4f}\")\n",
    "print(f\"Derivative at x={x_point.item():.4f}: {x_point.grad.item():.4f}\")\n",
    "\n",
    "print(f\"Exact value at x={x_point.item():.4f}: {func(x_point).item():.4f}\")\n",
    "print(f\"Derivative at x={x_point.item():.4f}: {d_func_dx(x_point).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
